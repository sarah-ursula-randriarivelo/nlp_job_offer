{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbe0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%run database_connection_.ipynb import df_database_connection as df\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_row', None)\n",
    "\n",
    "df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stopword import stop_words\n",
    "%run database_connection_.ipynb import df_database_connection as df\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean text to prepare the matching with keyword_mapping.\n",
    "        - Convert into lowercase\n",
    "        - delete all punctuations (comma, dot, etc...)\n",
    "        - Normalise spaces\n",
    "        - Preserving commonly composed terms like \"data scientist\", \"stagiaire informatique\") \n",
    "   \n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. Convert text to lowercase\n",
    "    text= text.lower()\n",
    "    \n",
    "    # normalise spaces\n",
    "    text = re.sub(r'\\\\n+', '\\n', text)\n",
    "\n",
    "    # 2. # Replace underscores, slashes with spaces (to separate words)\n",
    "    text = re.sub(r\"[-_/]\", \" \", text)\n",
    "\n",
    "    # 3. # Delete all elements that is not a letter or a digit (with accents), a space, or a number\n",
    "    text = re.sub(r\"[^a-zàâäéèêëîïôöùûüç0-9\\s]\", \" \", text)\n",
    "\n",
    "    # - replace digits with an empty space\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "\n",
    "    # 4. Normalise multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # - replacing unecessary terms like 'telma, galaxy', etc with an empty character\n",
    "    text = re.sub(r\"(telma|galaxy|diego|tamatave|axian|antananarivo|mahajanga|toamasina|andraharo|zone|futura|shore|andranomena|immeuble|mdg|batiment ariane|batiment|ariane|tana|antsirabe|fianarantsoa|kube|majunga|tolagnaro|er etage|mdg|mdg campus|campus)\", '', text)\n",
    "\n",
    "    # Removing french articles inside titles\n",
    "    text = text.split()\n",
    "    filtered_word = []\n",
    "    for word in text:\n",
    "        if word not in stop_words:\n",
    "            word = filtered_word.append(word)\n",
    "    text = ' '.join(filtered_word)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778cff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run database_connection_.ipynb import df_database_connection as df\n",
    "\n",
    "\n",
    "# apply the cleaning function for each column\n",
    "for columns in df.select_dtypes('object').columns:\n",
    "    if \"profil_clean\" not in columns: \n",
    "        df[columns] = df[columns].apply(clean_text)\n",
    "\n",
    "df_clean_text = df \n",
    "\n",
    "df_clean_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
